**********************************************************************
* This framework is  under the GNU License.
*
* All rights reserved 
*
*This file is written by Bissan AUDEH
*For information, feedback, questions, please contact bissana@gmail.com
*
*
*
***********************************************************************

About this document:
-----------------------
This is a detailed description about a scrapping and anonymisation framework for web forums. This framework is composed of several main and auxiliary scripts. It has been designed as part of the Vigi4Med project (http://vigi4med.com/) to scrap medical posts.
This tool allows to :
1- Scrap posts from web forums to an RDF graph with the n-triple format 
2- Specify the data you want to scrap by defining Xpathes within a configuration file (one configuration file per site)
3- Keep a copy from each scrapped HTML page within a database (optional) 
4- Anonymise scrapped data (optional)

List of requirements
-------------------------
1- PHP installation. It is recommended to run the scripts from command line 
 1-1 Please make sure to have curl installed in the system and curl module for php also installed
  -> In ubuntu: 
   sudo apt-get install curl
   sudo apt-get install php-curl
 1-2 Please make sur to have the DOM module installed for php
  -> In ubuntu: sudo apt-get install php-dom
  (Note: restart apache server after installing php modules)
2- Perl installation for the proxy (if you want to use the proxy).
3- Berkeley DB (if you want to use the proxy).

How to use Vigi4Med Scraper
-------------------------
1- For each website, provide a list of the forums you want to scrap
2- Create the configuration file of the website (please follow the example of the file config_example.ini)
3- run the proxy (optional but recommended)
4- run the scrapping script: vigi4Med_MainScraper.php
5- run the anonymisation script(optional but recommended to protect privacy): vigi4Med_Anonymization.php
Please note that this framework was designed to be as precise as possible. The manual steps (list of forums, configuration file, and consecutive execution of scripts) was intended to validate and verify each generated part. 
 
Detailed description for using vigi4Med Scraper:
------------------------
1- Prepare the list of forums we want to scrap from a web site. 

2- Prepare the configuration file. Please follow the instruction in the file Readme_Configuration.txt for this step

3- The use of the proxy is optional but highly recommended. The proxy organizes a delay between sequential requests, and keeps a copy of the scraped pages in its cach database, which is very useful if the scrapping experiment is to be restarted.  
To run the proxy, you have to execute the following command (in command line). 
  -----------------------------------------------------------
 |	
 |	perl proxy.pl     
 |							   
 -----------------------------------------------------------
 This script takes as optional input the number of the port. If not give, the default is 3129, as output it gives a description of each requested page.
 I recommend that the script be launched in "nohup" mode and the output directed to a file. Ex (on mac os):
  -----------------------------------------------------------
 |	
 |	nohup perl proxy.pl > nohup/2015_6_24 2>&1&    
 |							   
 -----------------------------------------------------------
*IMPORTANT : Make sure to type correctly the name of the proxy in the configuration file.
 
 4- Scrap: Once the proxy is running correctly, and the configuration file is ready, you can run the scrapping function. Please make sure that the script has access to your disk in read/write/execution mode.
 Input of the script : the configuration file
 Output :
 -Information about scrapped pagers (number, time)
 -The RDF file (outputNameGraph.n3)
 -Logs
 I recommend also to run the script in nohup mode as following (on mac os):
 -------------------------------------------------------------
 |									  
 |	nohup php vigi4Med_MainScraper.php conigFilesName.ini > nohup/siteName_date 2>&1&	  
 |													  
 -------------------------------------------------------------
 
 5- Anonimization : 
 The anonymization script (vigi4Med_Anonymization.php) takes as input the RDF file generated by the step 4. Optionally, you can also use the name of the user to ignore (for example "deleted profile"), this will tell the script that this is not a pseudo of a user. For more information about the use of this script and other optional inputs please see the file Readme_Anonymisation.txt
 Examples about running the anonymisation script :
 -----------------------------
 |									    
 |	vigi4Med_Anonymization.php Graph.n3								    
 |													  	    
 -----------------------------
 
 
 
 
 
 
 
 
 
 
